{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab53bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315464ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────── CONFIG ───────\n",
    "IMG_HEIGHT, IMG_WIDTH = 50, 200\n",
    "MAX_LABEL_LEN = 10\n",
    "CHARS = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dab3a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_TO_IDX = {c: i + 1 for i, c in enumerate(CHARS)}  # 1-indexed (CTC blank = 0)\n",
    "IDX_TO_CHAR = {0: ''}  # blank\n",
    "IDX_TO_CHAR.update({i + 1: c for i, c in enumerate(CHARS)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c811c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH  = r\"C:\\Users\\tejas\\Downloads\\archive (1)\\Licplatesrecognition_train.csv\"\n",
    "IMAGE_DIR = r\"C:\\Users\\tejas\\Downloads\\archive (1)\\Licplatesrecognition_train\\license_plates_recognition_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b051c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────── LOAD DATA ───────\n",
    "print(\"Loading dataset …\")\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "images, texts = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915e5f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df.iterrows():\n",
    "    img_path = os.path.join(IMAGE_DIR, row[\"img_id\"])\n",
    "    text = row[\"text\"].strip()\n",
    "\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        continue\n",
    "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    img = img.astype(\"float32\") / 255.0\n",
    "\n",
    "    images.append(np.expand_dims(img, axis=-1))\n",
    "    texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7709035",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "X = np.array(images, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49094903",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ─────── LABEL ENCODING ───────\n",
    "def encode_and_pad_labels(texts, maxlen, char_to_idx):\n",
    "    num_classes = len(char_to_idx) + 1\n",
    "    safe_labels = []\n",
    "    for t in texts:\n",
    "        cleaned = [char_to_idx[c] for c in t if c in char_to_idx]\n",
    "        deduped, prev = [], None\n",
    "        for c in cleaned:\n",
    "            if c != prev:\n",
    "                deduped.append(c)\n",
    "                prev = c\n",
    "        deduped = [i for i in deduped if 0 < i < num_classes - 1][:maxlen]\n",
    "        padded  = deduped + [0] * (maxlen - len(deduped))\n",
    "        safe_labels.append(padded)\n",
    "    return np.array(safe_labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93abb9a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "Y = encode_and_pad_labels(texts, MAX_LABEL_LEN, CHAR_TO_IDX)\n",
    "assert np.max(Y) < len(CHAR_TO_IDX) + 1, \"Labels contain invalid indices!\"\n",
    "print(\"Dataset shape:\", X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53139d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ─────── MODEL ───────\n",
    "def build_crnn_model():\n",
    "    inp_img = layers.Input((IMG_HEIGHT, IMG_WIDTH, 1), name=\"input_image\")\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(inp_img)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Reshape((IMG_WIDTH // 4, (IMG_HEIGHT // 4) * 64))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
    "    y_pred = layers.Dense(len(CHAR_TO_IDX) + 1, activation=\"softmax\", name=\"y_pred\")(x)\n",
    "    return inp_img, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32730f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_img, y_pred = build_crnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9382ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────── CTC LOSS ───────\n",
    "labels_in = layers.Input(shape=(MAX_LABEL_LEN,), name=\"labels\")\n",
    "input_len = layers.Input(shape=(1,), name=\"input_len\")\n",
    "label_len = layers.Input(shape=(1,), name=\"label_len\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0def18bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctc_output = layers.Lambda(\n",
    "    lambda x: K.ctc_batch_cost(\n",
    "        tf.cast(x[1], dtype='int32'),  # labels\n",
    "        x[0],                          # y_pred\n",
    "        x[2],                          # input_len\n",
    "        x[3]                           # label_len\n",
    "    ),\n",
    "    output_shape=(1,),\n",
    "    name=\"ctc\"\n",
    ")([y_pred, labels_in, input_len, label_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcef588",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model(\n",
    "    inputs=[inp_img, labels_in, input_len, label_len],\n",
    "    outputs=ctc_output\n",
    ")\n",
    "model.compile(optimizer=\"adam\", loss={\"ctc\": lambda y_true, y_pred: y_pred})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab68ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────── TRAINING ───────\n",
    "X_tr, X_val, Y_tr, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "train_dict = {\n",
    "    \"input_image\": X_tr,\n",
    "    \"labels\": Y_tr,\n",
    "    \"input_len\": np.ones((X_tr.shape[0], 1)) * (IMG_WIDTH // 4),\n",
    "    \"label_len\": np.array([[np.count_nonzero(y)] for y in Y_tr])\n",
    "}\n",
    "val_dict = {\n",
    "    \"input_image\": X_val,\n",
    "    \"labels\": Y_val,\n",
    "    \"input_len\": np.ones((X_val.shape[0], 1)) * (IMG_WIDTH // 4),\n",
    "    \"label_len\": np.array([[np.count_nonzero(y)] for y in Y_val])\n",
    "}\n",
    "dummy_tr = np.zeros((X_tr.shape[0], 1))\n",
    "dummy_val = np.zeros((X_val.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fae9cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training model …\")\n",
    "model.fit(train_dict, dummy_tr, validation_data=(val_dict, dummy_val), epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7051d5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ─────── SAVE INFERENCE MODEL ───────\n",
    "predict_model = models.Model(inp_img, y_pred)\n",
    "predict_model.save(\"predict_crnn_model.keras\")\n",
    "print(\"[ok] Inference model saved as predict_crnn_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f77fd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ─────── DECODING FUNCTION (IMPROVED) ───────\n",
    "def decode_batch(images, beam_w=10):\n",
    "    preds = predict_model.predict(images)\n",
    "    print(\"Preds shape:\", preds.shape)\n",
    "    print(\"Sample prediction argmax:\", np.argmax(preds[0], axis=-1))\n",
    "\n",
    "    decoded, _ = K.ctc_decode(\n",
    "        preds,\n",
    "        input_length=np.ones(preds.shape[0]) * preds.shape[1],\n",
    "        greedy=False,\n",
    "        beam_width=beam_w,\n",
    "        top_paths=1\n",
    "    )\n",
    "\n",
    "    texts = []\n",
    "    for i, seq in enumerate(decoded[0].numpy()):\n",
    "        print(f\"Decoded indices ({i}):\", seq)\n",
    "        chars = [IDX_TO_CHAR.get(idx, '') for idx in seq if idx > 0]\n",
    "        result = ''.join(chars)\n",
    "        print(f\"Decoded string ({i}):\", result)\n",
    "        texts.append(result)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633a8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────── SANITY CHECK ───────\n",
    "print(\"\\nDecoding 10 validation samples …\")\n",
    "sample_imgs = X_val[:10]\n",
    "decoded_texts = decode_batch(sample_imgs, beam_w=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b3985",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, txt in enumerate(decoded_texts):\n",
    "    gt = \"\".join([IDX_TO_CHAR.get(c, '') for c in Y_val[i] if c > 0])\n",
    "    print(f\"GT: {gt:<10} | Pred: {txt}\")\n",
    "\n",
    "    plt.imshow(sample_imgs[i].squeeze(), cmap=\"gray\")\n",
    "    plt.title(f\"GT: {gt} | Pred: {txt}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
